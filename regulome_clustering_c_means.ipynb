{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leiden followed by C means clustering of regulome\n",
    "\n",
    "First make a proof of concept using igraph\n",
    "\n",
    "Questions:\n",
    "- How to measure distance\n",
    "- How to measure membership\n",
    "- How to treat small clusters - leave and expand or remove and add nodes to new?\n",
    "\n",
    "If it works:\n",
    "- make faster implementation\n",
    "\n",
    "\n",
    "Problems:\n",
    "- current distance measure: \n",
    "    - favors large clusters and nodes with high degree\n",
    "    - maybe make measure of distance based on the number of nodes in the cluster\n",
    "        - in a cluster of 10, 10 edges would make highly conncted to cluster, but in cluster of 100, 10 edges might not.\n",
    "        - ideally, if node connected to all nodes, with 1 PPV - distance should be nearing 0, if no connection should be 1\n",
    "        - 1 - (n_nodes_cluster/sum(distances))\n",
    "            - this will favor smaller clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import igraph as ig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from compress_pickle import load, dump\n",
    "from statistics import mean, median\n",
    "from IPython.display import clear_output\n",
    "from c_means_clustering import network_c_means\n",
    "from copy import deepcopy\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log10\n",
    "\n",
    "plt.style.use('bmh')\n",
    "\n",
    "def open_pickle(file):\n",
    "    with open(path+file, 'rb') as pickle_file:\n",
    "        return load(path=pickle_file, compression='infer')\n",
    "\n",
    "path = './files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load regulome\n",
    "regulome_network_edges = pd.read_csv(filepath_or_buffer=path+'/human_regulome_pd.gz', compression='infer')\n",
    "regulome_network_edges = regulome_network_edges.astype({'ProteinAid': 'str', 'ProteinBid':'str'})\n",
    "\n",
    "regulome_graph = ig.Graph.DataFrame(regulome_network_edges, directed=False, use_vids=False)\n",
    "# msigdb_c3_tft_dict = open_pickle('msigdb_c3_tft_dict.pkl')\n",
    "proteins = pd.concat([regulome_network_edges['ProteinAid'], regulome_network_edges['ProteinBid']]).unique()\n",
    "\n",
    "# del regulome_network_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def leiden_clustering(graph, res, b, n_iter):\n",
    "#     return graph.community_leiden(objective_function='modularity',\n",
    "#                             weights='PPV',\n",
    "#                             resolution=res,\n",
    "#                             beta=b,\n",
    "#                             n_iterations=n_iter)\n",
    "\n",
    "# leiden_clusters = leiden_clustering(regulome_graph, 4, 0.1, 10)\n",
    "# clusters_dict = {n:set(regulome_graph.vs[node]['name'] for node in cluster) for (n, cluster) in enumerate(leiden_clusters)}\n",
    "\n",
    "# with open(path+'c_means_leiden_clusters.gz', 'wb') as file:\n",
    "#     dump(clusters_dict, file, compression='infer')\n",
    "\n",
    "clusters_dict = open_pickle(\"c_means_leiden_clusters.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden_cluster_sizes = [len(cluster) for cluster in clusters_dict.values()]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[6,4])\n",
    "\n",
    "\n",
    "sns.histplot(leiden_cluster_sizes, binwidth=5, ax=ax)\n",
    "fig.suptitle(\"Size distribution of Leiden clusters\")\n",
    "ax.set_xlabel(\"Cluster size\")\n",
    "ax.axvline(x=10, c='r', lw=2)\n",
    "# fig.set_xlim([0, 20])\n",
    "fig.savefig(\"./images/LiedenClustersDistr.png\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_leiden = [cluster for cluster in leiden_cluster_sizes if cluster > 10]\n",
    "\n",
    "print(f\"Number of Leiden cluster: {len(leiden_cluster_sizes)}\")\n",
    "print(f\"Number of filtered Leiden cluster: {len(filtered_leiden)}\")\n",
    "print(f\"Median cluster size: {median(filtered_leiden)}\")\n",
    "print(f\"Mean cluster size: {mean(filtered_leiden)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'path_lengths_dict.gz', 'rb') as file:\n",
    "    path_lengths_dict = load(file, compression='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network_c_means' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork_c_means\u001b[49m(regulome_graph, deepcopy(clusters_dict), \u001b[38;5;241m2\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, distance_measure\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, path_lengths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'network_c_means' is not defined"
     ]
    }
   ],
   "source": [
    "results = network_c_means(regulome_graph, deepcopy(clusters_dict), 2, n_iter=1, optimize=True, distance_measure='edge_rate', path_lengths=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = sns.histplot([len(cluster) for cluster in results[0][1].values()])\n",
    "fig.set_xlim([0, 1000])\n",
    "plt.show()\n",
    "\n",
    "sns.lineplot(results[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array([val for val in results['346909'].values()])\n",
    "perc = np.percentile(res, 95)\n",
    "print(perc)\n",
    "\n",
    "print(len([cluster for (cluster, membership) in results['346909'].items() if membership >= perc]))\n",
    "\n",
    "fig = sns.histplot(results['346909'])\n",
    "fig.axvline(x=perc, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [node for node in regulome_graph.vs['name']]\n",
    "\n",
    "with open(path+'path_lengths.gz', 'rb') as file:\n",
    "    path_lengths = load(file, compression='infer')\n",
    "\n",
    "path_lengths = path_lengths[0]\n",
    "path_lengths_dict = dict()\n",
    "n_nodes = len(nodes)\n",
    "for (node_number, node) in enumerate(nodes):\n",
    "    clear_output()\n",
    "    print(f'{node_number}/{n_nodes}')\n",
    "    path_lengths_dict[node] = {\n",
    "        other_node: round(path_lengths, 2)\n",
    "        for (other_node, path_lengths) in zip(nodes, path_lengths[:n_nodes])\n",
    "    }\n",
    "    path_lengths = path_lengths[n_nodes:]\n",
    "del path_lengths\n",
    "\n",
    "with open(path+'path_lengths_dict.gz', 'wb') as file:\n",
    "    dump(path_lengths_dict,path+'path_lengths_dict.gz', compression='infer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "network_c_means() got multiple values for argument 'n_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m most_connected_memberships \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m m_values:\n\u001b[0;32m---> 14\u001b[0m     most_connected_memberships[m] \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork_c_means\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregulome_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmost_connected_proteins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclusters_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance_measure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medge_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m least_connected_memberships \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m m_values:\n",
      "\u001b[0;31mTypeError\u001b[0m: network_c_means() got multiple values for argument 'n_iter'"
     ]
    }
   ],
   "source": [
    "from math import log10\n",
    "from c_means_clustering import gather_neighbors, node_iteration\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "protein_edges = pd.concat([regulome_network_edges['ProteinAid'], regulome_network_edges['ProteinBid']]).value_counts()\n",
    "most_connected_proteins = tuple(protein_edges.index[:5])\n",
    "least_connected_proteins = tuple(protein_edges[protein_edges>2].index[-5:])\n",
    "\n",
    "# results = network_c_means(regulome_graph, deepcopy(clusters_dict), 2, n_iter=1, optimize=True, distance_measure='edge_rate', path_lengths=None)\n",
    "m_values = [2]\n",
    "\n",
    "most_connected_memberships = dict()\n",
    "for m in m_values:\n",
    "    most_connected_memberships[m] = network_c_means(regulome_graph, most_connected_proteins, deepcopy(clusters_dict), m, n_iter=1, optimize=False, distance_measure='edge_rate', path_lengths=None)\n",
    "\n",
    "\n",
    "least_connected_memberships = dict()\n",
    "for m in m_values:\n",
    "    least_connected_memberships[m] = network_c_means(regulome_graph, least_connected_proteins, deepcopy(clusters_dict), m, n_iter=1, optimize=False, distance_measure='edge_rate', path_lengths=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = '336275'\n",
    "print(protein_edges[protein])\n",
    "m = 4\n",
    "\n",
    "perc = np.percentile(np.array(list(least_connected_memberships[m][protein].values())), 95)\n",
    "print(perc)\n",
    "fig = sns.histplot(least_connected_memberships[m][protein])\n",
    "fig.axvline(x=perc, c = 'r')\n",
    "fig.axhline(y=1, c='b')\n",
    "fig.set_ylim([0, 100])\n",
    "\n",
    "see= [t for t in (least_connected_memberships[m][protein].values()) if t > perc]\n",
    "print(see)\n",
    "# sorted(tuple(least_connected_memberships[m][protein].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_connected_memberships\n",
    "\n",
    "# Manually extract the keys and values\n",
    "rows = [\n",
    "    (m, protein, membership)\n",
    "    for (m, proteins) in most_connected_memberships.items()\n",
    "    for (protein, memberships) in proteins.items()\n",
    "    for membership in memberships.values()\n",
    "]\n",
    "\n",
    "most_connected_df = pd.DataFrame(rows, columns=['fuzzy_m', 'Proteinid', 'membership'])\n",
    "\n",
    "fig = sns.FacetGrid(most_connected_df, col='fuzzy_m', row='Proteinid')\n",
    "fig.map(sns.histplot, 'membership')\n",
    "fig.figure.subplots_adjust(top=0.925)\n",
    "fig.set_xlabels('Membership (log10)')\n",
    "fig.figure.suptitle(\"Membership distribution of the 5 proteins with the highest degree\")\n",
    "fig.refline(y=1, c='r')\n",
    "# fig.savefig(\"./images/most_well_connected_sum_dist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# least_connected_memberships\n",
    "\n",
    "# Manually extract the keys and values\n",
    "rows = [\n",
    "    (m, protein, membership)\n",
    "    for (m, proteins) in least_connected_memberships.items()\n",
    "    for (protein, memberships) in proteins.items()\n",
    "    for membership in memberships.values()\n",
    "]\n",
    "\n",
    "least_connected_df = pd.DataFrame(rows, columns=['fuzzy_m', 'Proteinid', 'membership'])\n",
    "\n",
    "fig = sns.FacetGrid(least_connected_df, col='fuzzy_m', row='Proteinid')\n",
    "fig.map(sns.histplot, 'membership')\n",
    "fig.figure.subplots_adjust(top=0.925)\n",
    "fig.set_xlabels('Membership (log10)')\n",
    "fig.figure.suptitle(\"Membership distribution of the 5 proteins with the lowest degree (more than 5)\")\n",
    "fig.refline(y=1, c='r')\n",
    "\n",
    "# fig.savefig(\"./images/least_connected_sum_dist_not1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def calc_dist(graph, node, clusters):\n",
    "    node_distances = dict()\n",
    "    neighbors = set(graph.neighbors(node))\n",
    "\n",
    "    for (cluster_id, cluster) in clusters.items():\n",
    "        connected_nodes = set(neighbors).intersection(cluster)\n",
    "\n",
    "        if len(connected_nodes) == 0: # no need if no connections\n",
    "            node_distances[cluster_id] = 1\n",
    "            continue\n",
    "\n",
    "        # get weights of each connection to nodes in the cluster\n",
    "        weights = [graph.es(graph.get_eid(node, connected_node))['PPV'] for connected_node in connected_nodes]\n",
    "        weights_sum = sum(chain.from_iterable(weights))\n",
    "\n",
    "        if weights_sum == 0: # dont need this myself, but a thing to look at if want to ship out later\n",
    "            node_distances[cluster_id] = 1\n",
    "            continue\n",
    "\n",
    "        node_distances[cluster_id] = 1 / weights_sum\n",
    "    return node_distances\n",
    "\n",
    "\n",
    "def calc_membership(node_distances, m):\n",
    "    node_memberships = dict()\n",
    "\n",
    "    for (cluster_id, d) in node_distances.items():         \n",
    "        fuzzy_exponent = 2 / (m - 1)\n",
    "\n",
    "        # give better name - denomintation or membership function  \n",
    "        membership_den = [(d / other_d) ** fuzzy_exponent for other_d in node_distances.values()]\n",
    "\n",
    "        node_memberships[cluster_id] = 1 / sum(membership_den)\n",
    "\n",
    "    return node_memberships\n",
    "\n",
    "\n",
    "def optimization_function(node_distances, node_memberships, m): # change function name\n",
    "    node_J = 0\n",
    "    for cluster_id in node_distances.keys():\n",
    "        node_J += node_memberships[cluster_id]**m * node_distances[cluster_id]**2\n",
    "    return node_J\n",
    "    \n",
    "\n",
    "def network_c_means(graph, clusters, m, optimize=False):\n",
    "    # add leiden here after \n",
    "\n",
    "    membership_dict = dict()\n",
    "    distances_dict = dict()\n",
    "    \n",
    "    if optimize:\n",
    "        Js = list()\n",
    "\n",
    "    for i in range(0, 10):\n",
    "        for node in graph.vs:\n",
    "            node = node['name']\n",
    "            node_distances = calc_dist(graph, node, clusters) # returns dictionary with distance to each cluster\n",
    "            node_memberships = calc_membership(node_distances, m) # adds memberships of node to dictionary\n",
    "\n",
    "            if optimize:\n",
    "                Js.append(optimization_function(node_distances, node_memberships, m))\n",
    "            distances_dict[node] = node_distances # maybe just add directly to dictionary\n",
    "            membership_dict[node] = node_memberships\n",
    "\n",
    "    \n",
    "\n",
    "    return Js\n",
    "\n",
    "memberships = network_c_means(regulome_graph, clusters_dict, 0.5, optimize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regulome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
